"""
ë³´ê³ ì„œ ìƒì„± API
GPTë¥¼ ì‚¬ìš©í•˜ì—¬ ì›Œí¬í”Œë¡œìš° ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ íˆ¬ì ë¶„ì„ ë³´ê³ ì„œë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
"""

from fastapi import APIRouter, HTTPException
from pydantic import BaseModel
from typing import List, Dict, Any, Optional
import json
from datetime import datetime
import logging

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

router = APIRouter()

class WorkflowResult(BaseModel):
    tool_used: Optional[str] = None
    result: Any = None
    status: Optional[str] = None

class ReportRequest(BaseModel):
    workflowResults: List[WorkflowResult]
    timestamp: str
    totalStocks: int = 0
    filteredStocks: int = 0

@router.post("/generate-report")
async def generate_report(request: ReportRequest):
    """
    ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ íˆ¬ì ë¶„ì„ ë³´ê³ ì„œë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    """
    try:
        logger.info("ë³´ê³ ì„œ ìƒì„± ìš”ì²­ ìˆ˜ì‹ ")
        logger.info(f"ë¶„ì„ëœ ì¢…ëª© ìˆ˜: {request.totalStocks}")
        logger.info(f"í•„í„°ë§ëœ ì¢…ëª© ìˆ˜: {request.filteredStocks}")
        
        # ì›Œí¬í”Œë¡œìš° ê²°ê³¼ ë¶„ì„
        analysis_data = analyze_workflow_results(request.workflowResults)
        
        # ë³´ê³ ì„œ ìƒì„±
        report_content = generate_investment_report(
            analysis_data,
            request.totalStocks,
            request.filteredStocks,
            request.timestamp
        )
        
        logger.info("ë³´ê³ ì„œ ìƒì„± ì™„ë£Œ")
        return report_content
        
    except Exception as e:
        logger.error(f"ë³´ê³ ì„œ ìƒì„± ì‹¤íŒ¨: {str(e)}")
        raise HTTPException(status_code=500, detail=f"ë³´ê³ ì„œ ìƒì„± ì‹¤íŒ¨: {str(e)}")

def analyze_workflow_results(workflow_results: List[WorkflowResult]) -> Dict[str, Any]:
    """ì›Œí¬í”Œë¡œìš° ê²°ê³¼ë¥¼ ë¶„ì„í•˜ì—¬ ë³´ê³ ì„œ ë°ì´í„°ë¡œ ë³€í™˜"""
    analysis = {
        "all_tickers": None,
        "filtered_stocks": None,
        "market_news": None,
        "foreign_investment": None,
        "sector_analysis": None
    }
    
    for result in workflow_results:
        if not result.tool_used or not result.result:
            continue
            
        try:
            # JSON ë¬¸ìì—´ì¸ ê²½ìš° íŒŒì‹±
            if isinstance(result.result, str):
                data = json.loads(result.result)
            else:
                data = result.result
                
            if result.tool_used == "get_all_tickers":
                analysis["all_tickers"] = data
            elif result.tool_used == "filter_stocks_by_fundamentals":
                analysis["filtered_stocks"] = data
            elif result.tool_used == "get_market_news":
                analysis["market_news"] = data
            elif result.tool_used == "get_foreign_investment":
                analysis["foreign_investment"] = data
            elif result.tool_used == "get_sector_performance":
                analysis["sector_analysis"] = data
                
        except json.JSONDecodeError:
            logger.warning(f"JSON íŒŒì‹± ì‹¤íŒ¨: {result.tool_used}")
            continue
        except Exception as e:
            logger.warning(f"ê²°ê³¼ ë¶„ì„ ì‹¤íŒ¨ {result.tool_used}: {str(e)}")
            continue
    
    return analysis

def generate_investment_report(
    analysis_data: Dict[str, Any],
    total_stocks: int,
    filtered_stocks: int,
    timestamp: str
) -> str:
    """ë¶„ì„ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ íˆ¬ì ë¶„ì„ ë³´ê³ ì„œ ìƒì„±"""
    
    report_sections = []
    
    # 1. ë³´ê³ ì„œ í—¤ë”
    report_sections.append(f"""# íˆ¬ì ë¶„ì„ ë³´ê³ ì„œ

**ìƒì„±ì¼ì‹œ:** {timestamp}  
**ë¶„ì„ ëŒ€ìƒ:** ì „ì²´ {total_stocks}ê°œ ì¢…ëª©  
**í•„í„°ë§ ê²°ê³¼:** {filtered_stocks}ê°œ ìš°ëŸ‰ ì¢…ëª© ì„ ë³„  

---
""")
    
    # 2. ìš”ì•½
    summary = generate_summary(analysis_data, total_stocks, filtered_stocks)
    report_sections.append(f"""## ğŸ“Š ë¶„ì„ ìš”ì•½

{summary}

---
""")
    
    # 3. ì„ ë³„ëœ ì¢…ëª© ë¶„ì„
    if analysis_data.get("filtered_stocks"):
        stock_analysis = generate_stock_analysis(analysis_data["filtered_stocks"])
        report_sections.append(f"""## ğŸ¯ ì„ ë³„ ì¢…ëª© ë¶„ì„

{stock_analysis}

---
""")
    
    # 4. ì‹œì¥ ë™í–¥ ë¶„ì„
    if analysis_data.get("market_news"):
        market_analysis = generate_market_analysis(analysis_data["market_news"])
        report_sections.append(f"""## ğŸ“ˆ ì‹œì¥ ë™í–¥ ë¶„ì„

{market_analysis}

---
""")
    
    # 5. ì™¸êµ­ì¸ íˆ¬ì ë™í–¥
    if analysis_data.get("foreign_investment"):
        foreign_analysis = generate_foreign_investment_analysis(analysis_data["foreign_investment"])
        report_sections.append(f"""## ğŸŒ ì™¸êµ­ì¸ íˆ¬ì ë™í–¥

{foreign_analysis}

---
""")
    
    # 6. íˆ¬ì ì œì•ˆ
    recommendations = generate_investment_recommendations(analysis_data, filtered_stocks)
    report_sections.append(f"""## ğŸ’¡ íˆ¬ì ì œì•ˆ

{recommendations}

---

**ë©´ì±…ì¡°í•­:** ë³¸ ë³´ê³ ì„œëŠ” ê³µê°œëœ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ í•œ ë¶„ì„ ê²°ê³¼ì´ë©°, íˆ¬ì ê²°ì • ì‹œ ì¶”ê°€ì ì¸ ë¶„ì„ê³¼ ì „ë¬¸ê°€ ìƒë‹´ì´ í•„ìš”í•©ë‹ˆë‹¤.
""")
    
    return "\n".join(report_sections)

def generate_summary(analysis_data: Dict[str, Any], total_stocks: int, filtered_stocks: int) -> str:
    """ë¶„ì„ ìš”ì•½ ìƒì„±"""
    
    summary_points = []
    
    if total_stocks > 0 and filtered_stocks > 0:
        selectivity = round((filtered_stocks / total_stocks) * 100, 1)
        summary_points.append(f"â€¢ ì „ì²´ {total_stocks}ê°œ ì¢…ëª© ì¤‘ {filtered_stocks}ê°œ ì¢…ëª© ì„ ë³„ (ì„ ë³„ë¥ : {selectivity}%)")
    
    if analysis_data.get("filtered_stocks") and analysis_data["filtered_stocks"].get("stocks"):
        top_stock = analysis_data["filtered_stocks"]["stocks"][0] if analysis_data["filtered_stocks"]["stocks"] else None
        if top_stock:
            summary_points.append(f"â€¢ ìµœìš°ì„  ì¶”ì²œ ì¢…ëª©: {top_stock.get('name', 'N/A')} (PER: {top_stock.get('per', 'N/A')})")
    
    if analysis_data.get("market_news") and analysis_data["market_news"].get("risk_assessment"):
        risk = analysis_data["market_news"]["risk_assessment"]
        summary_points.append(f"â€¢ ì •ì¹˜ì  ë¦¬ìŠ¤í¬: {risk.get('political_risk', 'N/A')}, ì‚°ì—… ë¦¬ìŠ¤í¬: {risk.get('industry_risk', 'N/A')}")
    
    if not summary_points:
        summary_points.append("â€¢ ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ í•œ íˆ¬ì ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    return "\n".join(summary_points)

def generate_stock_analysis(filtered_data: Dict[str, Any]) -> str:
    """ì„ ë³„ ì¢…ëª© ë¶„ì„ ìƒì„±"""
    
    if not filtered_data.get("stocks"):
        return "ì„ ë³„ëœ ì¢…ëª© ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    
    stocks = filtered_data["stocks"][:5]  # ìƒìœ„ 5ê°œ ì¢…ëª©ë§Œ
    criteria = filtered_data.get("filter_criteria", {})
    
    analysis = []
    
    # í•„í„°ë§ ê¸°ì¤€
    if criteria:
        analysis.append("### ğŸ“‹ ì„ ë³„ ê¸°ì¤€")
        criteria_text = []
        if criteria.get("per_max"):
            criteria_text.append(f"PER â‰¤ {criteria['per_max']}")
        if criteria.get("pbr_max"):
            criteria_text.append(f"PBR â‰¤ {criteria['pbr_max']}")
        if criteria.get("roe_min"):
            criteria_text.append(f"ROE â‰¥ {criteria['roe_min']}%")
        if criteria.get("market_cap_min"):
            criteria_text.append(f"ì‹œê°€ì´ì•¡ â‰¥ {criteria['market_cap_min']}ì–µì›")
        
        analysis.append("â€¢ " + ", ".join(criteria_text))
        analysis.append("")
    
    # ìƒìœ„ ì¢…ëª© ë¶„ì„
    analysis.append("### ğŸ† TOP 5 ì¶”ì²œ ì¢…ëª©")
    analysis.append("")
    
    for i, stock in enumerate(stocks, 1):
        analysis.append(f"**{i}. {stock.get('name', 'N/A')} ({stock.get('ticker', 'N/A')})**")
        analysis.append(f"- PER: {stock.get('per', 'N/A')}, PBR: {stock.get('pbr', 'N/A')}")
        analysis.append(f"- ROE: {stock.get('roe', 'N/A')}%, ë°°ë‹¹ìˆ˜ìµë¥ : {stock.get('dividend_yield', 'N/A')}%")
        analysis.append(f"- ì‹œê°€ì´ì•¡: {stock.get('market_cap', 'N/A')}ì–µì›")
        analysis.append("")
    
    return "\n".join(analysis)

def generate_market_analysis(market_data: Dict[str, Any]) -> str:
    """ì‹œì¥ ë™í–¥ ë¶„ì„ ìƒì„±"""
    
    analysis = []
    
    # ë¦¬ìŠ¤í¬ í‰ê°€
    if market_data.get("risk_assessment"):
        risk = market_data["risk_assessment"]
        analysis.append("### ğŸš¨ ë¦¬ìŠ¤í¬ í‰ê°€")
        analysis.append(f"- ì •ì¹˜ì  ë¦¬ìŠ¤í¬: **{risk.get('political_risk', 'N/A')}**")
        analysis.append(f"- ì‚°ì—… ë¦¬ìŠ¤í¬: **{risk.get('industry_risk', 'N/A')}**")
        analysis.append(f"- ê·œì œ ë¦¬ìŠ¤í¬: **{risk.get('regulatory_risk', 'N/A')}**")
        analysis.append(f"- ê¸€ë¡œë²Œ ë¦¬ìŠ¤í¬: **{risk.get('global_risk', 'N/A')}**")
        analysis.append("")
    
    # ì„¹í„° ì „ë§
    if market_data.get("sector_trends"):
        analysis.append("### ğŸ“Š ì„¹í„°ë³„ ì „ë§")
        trends = market_data["sector_trends"]
        for sector, data in trends.items():
            outlook = data.get("outlook", "N/A")
            growth = data.get("growth_forecast", "N/A")
            driver = data.get("key_driver", "N/A")
            analysis.append(f"- **{sector}**: {outlook} ({growth}) - {driver}")
        analysis.append("")
    
    # ì£¼ìš” ë‰´ìŠ¤
    if market_data.get("major_news"):
        analysis.append("### ğŸ“° ì£¼ìš” ë‰´ìŠ¤")
        news_list = market_data["major_news"][:3]  # ìƒìœ„ 3ê°œ
        for news in news_list:
            date = news.get("date", "N/A")
            title = news.get("title", "N/A")
            impact = news.get("impact", "N/A")
            analysis.append(f"- **{date}**: {title} ({impact})")
        analysis.append("")
    
    return "\n".join(analysis) if analysis else "ì‹œì¥ ë¶„ì„ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

def generate_foreign_investment_analysis(foreign_data: Dict[str, Any]) -> str:
    """ì™¸êµ­ì¸ íˆ¬ì ë™í–¥ ë¶„ì„ ìƒì„±"""
    
    analysis = []
    
    if foreign_data.get("net_buying"):
        analysis.append("### ğŸ’° ì™¸êµ­ì¸ íˆ¬ì í˜„í™©")
        analysis.append(f"- ìˆœë§¤ìˆ˜: **{foreign_data.get('net_buying', 'N/A')}**")
        analysis.append(f"- ë§¤ìˆ˜: {foreign_data.get('buying', 'N/A')}")
        analysis.append(f"- ë§¤ë„: {foreign_data.get('selling', 'N/A')}")
        analysis.append(f"- ë³´ìœ ë¹„ì¤‘: {foreign_data.get('ownership_ratio', 'N/A')}")
        analysis.append("")
        
        # í•´ì„
        net_buying = foreign_data.get("net_buying", "0")
        if "ì¡°" in str(net_buying) or (isinstance(net_buying, str) and any(char.isdigit() for char in net_buying)):
            analysis.append("**ë¶„ì„**: ì™¸êµ­ì¸ì˜ ìˆœë§¤ìˆ˜ì„¸ê°€ ê´€ì°°ë˜ê³  ìˆì–´ ì‹œì¥ì— ê¸ì •ì  ì‹ í˜¸ë¡œ ì‘ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        else:
            analysis.append("**ë¶„ì„**: ì™¸êµ­ì¸ íˆ¬ì ë™í–¥ì„ ì§€ì†ì ìœ¼ë¡œ ëª¨ë‹ˆí„°ë§í•  í•„ìš”ê°€ ìˆìŠµë‹ˆë‹¤.")
    
    return "\n".join(analysis) if analysis else "ì™¸êµ­ì¸ íˆ¬ì ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

def generate_investment_recommendations(analysis_data: Dict[str, Any], filtered_stocks: int) -> str:
    """íˆ¬ì ì œì•ˆ ìƒì„±"""
    
    recommendations = []
    
    if filtered_stocks > 0:
        recommendations.append("### ğŸ¯ ë‹¨ê¸° íˆ¬ì ì „ëµ")
        recommendations.append(f"1. **ë¶„ì‚° íˆ¬ì**: ì„ ë³„ëœ {filtered_stocks}ê°œ ì¢…ëª© ì¤‘ 3-5ê°œ ì¢…ëª©ìœ¼ë¡œ í¬íŠ¸í´ë¦¬ì˜¤ êµ¬ì„±")
        recommendations.append("2. **ì €í‰ê°€ ì¢…ëª© ì¤‘ì‹¬**: PER, PBRì´ ë‚®ìœ¼ë©´ì„œ ROEê°€ ë†’ì€ ì¢…ëª© ìš°ì„  ê³ ë ¤")
        recommendations.append("3. **ë¦¬ìŠ¤í¬ ê´€ë¦¬**: ì‹œê°€ì´ì•¡ ê·œëª¨ì™€ ë°°ë‹¹ìˆ˜ìµë¥ ì„ ê³ ë ¤í•œ ì•ˆì •ì„± í™•ë³´")
        recommendations.append("")
        
        recommendations.append("### ğŸ“ˆ ì¤‘ì¥ê¸° íˆ¬ì ì „ëµ")
        
        # ì‹œì¥ ì „ë§ì— ë”°ë¥¸ ì œì•ˆ
        if analysis_data.get("market_news") and analysis_data["market_news"].get("sector_trends"):
            trends = analysis_data["market_news"]["sector_trends"]
            positive_sectors = [sector for sector, data in trends.items() 
                              if data.get("outlook") in ["ê¸ì •ì ", "íšŒë³µ"]]
            
            if positive_sectors:
                recommendations.append(f"1. **ì„±ì¥ ì„¹í„° ì§‘ì¤‘**: {', '.join(positive_sectors)} ê´€ë ¨ ì¢…ëª© ë¹„ì¤‘ í™•ëŒ€")
            else:
                recommendations.append("1. **ì•ˆì •ì„± ì¤‘ì‹¬**: í˜„ì¬ ì‹œì¥ ë¶ˆí™•ì‹¤ì„±ì„ ê³ ë ¤í•œ ë³´ìˆ˜ì  ì ‘ê·¼")
        else:
            recommendations.append("1. **ê· í˜• íˆ¬ì**: ë‹¤ì–‘í•œ ì„¹í„°ì— ë¶„ì‚° íˆ¬ìë¡œ ë¦¬ìŠ¤í¬ ë¶„ì‚°")
            
        recommendations.append("2. **ì •ê¸° ë¦¬ë°¸ëŸ°ì‹±**: ë¶„ê¸°ë³„ í¬íŠ¸í´ë¦¬ì˜¤ ì ê²€ ë° ì¡°ì •")
        recommendations.append("3. **ì¥ê¸° ê´€ì  ìœ ì§€**: ë‹¨ê¸° ë³€ë™ì„±ì— í”ë“¤ë¦¬ì§€ ì•ŠëŠ” íˆ¬ì ì›ì¹™ ê³ ìˆ˜")
    else:
        recommendations.append("í˜„ì¬ í•„í„°ë§ ì¡°ê±´ì— ë¶€í•©í•˜ëŠ” ì¢…ëª©ì´ ì œí•œì ì…ë‹ˆë‹¤. ì¡°ê±´ì„ ì™„í™”í•˜ì—¬ ì¬ë¶„ì„ì„ ê¶Œì¥í•©ë‹ˆë‹¤.")
    
    recommendations.append("")
    recommendations.append("### âš ï¸ ì£¼ì˜ì‚¬í•­")
    recommendations.append("- ë³¸ ë¶„ì„ì€ ê³¼ê±° ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•˜ë©°, ë¯¸ë˜ ìˆ˜ìµì„ ë³´ì¥í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤")
    recommendations.append("- íˆ¬ì ì „ ê°œë³„ ì¢…ëª©ì— ëŒ€í•œ ì¶”ê°€ ë¶„ì„ì´ í•„ìš”í•©ë‹ˆë‹¤")
    recommendations.append("- ê°œì¸ì˜ íˆ¬ì ì„±í–¥ê³¼ ëª©í‘œì— ë§ëŠ” í¬íŠ¸í´ë¦¬ì˜¤ êµ¬ì„±ì„ ê¶Œì¥í•©ë‹ˆë‹¤")
    
    return "\n".join(recommendations)
